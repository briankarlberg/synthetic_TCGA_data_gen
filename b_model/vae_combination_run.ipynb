{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665d7e4c-a1ed-46bd-82af-b1c2ea7021fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "# arg steps (0:54\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--index\", \"-i\", action=\"store\", required=True,\n",
    "                        help=\"combo index number\", type=int)\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "cohorts = [\"BRCA\"]\n",
    "otlr_cuts = [\"100k\", \"15k\", \"10k\", \"5k\", \"1k\", \"500\"]\n",
    "epochs = [15, 30, 45]\n",
    "batch_size = [32, 64, 128]\n",
    "version = '1d_model'\n",
    "\n",
    "combinations = list(itertools.product(cohorts, otlr_cuts, epochs, batch_size))\n",
    "\n",
    "combo_n = combinations[args.index]\n",
    "\n",
    "# replace combinations later in script with combo_n\n",
    "# 1Dconv, do not rebuild in memory - build from fresh kernel only (blank run)\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import (Input,  # want float.64 to go into this layer, two input layers (enc and dec)\n",
    "                          Conv1D,\n",
    "                          Dense,\n",
    "                          Conv1DTranspose,\n",
    "                          Flatten,\n",
    "                          Lambda,\n",
    "                          Reshape)\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print('libraries done')\n",
    "\n",
    "\n",
    "def build_model(latent_dim: int, train_norm: pd.DataFrame):\n",
    "    def compute_latent(x):\n",
    "        batch = K.shape(mu)[0]\n",
    "        dim = K.int_shape(mu)[1]\n",
    "        eps = K.random_normal(shape=(batch, dim))\n",
    "        return mu + K.exp(sigma / 2) * eps\n",
    "\n",
    "    def kl_reconstruction_loss(true, pred):\n",
    "        reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred))\n",
    "        kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "    encoder_input = Input(shape=(train_norm.shape[1], 1,))\n",
    "\n",
    "    encoder_conv = Conv1D(filters=8,\n",
    "                          kernel_size=3,\n",
    "                          activation='relu',\n",
    "                          padding='same')(encoder_input)\n",
    "\n",
    "    encoder_conv = Conv1D(filters=16,\n",
    "                          kernel_size=3,\n",
    "                          padding='same',\n",
    "                          activation='relu')(encoder_conv)\n",
    "\n",
    "    encoder = Flatten()(encoder_conv)\n",
    "\n",
    "    mu = Dense(latent_dim)(encoder)\n",
    "    sigma = Dense(latent_dim)(encoder)\n",
    "\n",
    "    latent_space = Lambda(compute_latent, output_shape=(latent_dim,))([mu, sigma])\n",
    "\n",
    "    conv_shape = K.int_shape(encoder_conv)\n",
    "\n",
    "    # Decoder start\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "    decoder = Dense(conv_shape[1] * conv_shape[2], activation='relu')(decoder_input)\n",
    "    decoder = Reshape((conv_shape[1], conv_shape[2]))(decoder)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=16,\n",
    "                                   kernel_size=3,\n",
    "                                   padding='same',\n",
    "                                   activation='relu')(decoder)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=8,\n",
    "                                   kernel_size=3,\n",
    "                                   activation='relu',\n",
    "                                   padding='same')(decoder_conv)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=1,\n",
    "                                   kernel_size=3,\n",
    "                                   activation='relu',\n",
    "                                   padding='same')(decoder_conv)\n",
    "\n",
    "    encoder = Model(encoder_input, latent_space)\n",
    "    decoder = Model(decoder_input, decoder_conv)\n",
    "    vae = Model(encoder_input, decoder(encoder(encoder_input)))\n",
    "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)  # blank model set for (pre)training\n",
    "    print('model built')\n",
    "    return encoder, decoder, vae\n",
    "\n",
    "\n",
    "def create_plots(cohort: str, otlr_cut: str, latent_dim: int, batch_size: int, date: str, version: str, history):\n",
    "    plt.plot(history.history['loss'], label=\"loss\")\n",
    "    plt.plot(history.history['val_loss'], label=\"val_loss\")\n",
    "    plt.title(cohort + ' embedding loss\\n1D convolutional VAE'\n",
    "              # ' pre-train\\n'+\n",
    "              )\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.annotate('Outliers cut value = ' + otlr_cut +\n",
    "                 '\\nlatent dim = ' + str(latent_dim) +\n",
    "                 '\\nBatch size = ' + str(batch_size) +\n",
    "                 '\\nConvolutional layer count = 2\\nTest ratio = .25\\nNormalization = MinMax',\n",
    "                 xy=(.4, .8), xycoords='figure fraction',\n",
    "                 horizontalalignment='left', verticalalignment='top',\n",
    "                 # fontsize=20\n",
    "                 )\n",
    "\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(\n",
    "        f'{cohort}_outlier_cut_{otlr_cut}_epochs_{str(epochs)}_latent_dim_{str(latent_dim)}_{date}_{version}.png')\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "for combination in combinations:\n",
    "    cohort = combination[0]\n",
    "    otlr_cut = combination[1]\n",
    "    epochs = combination[2]\n",
    "    batch_size = combination[3]\n",
    "    latent_dim = 100\n",
    "\n",
    "    # read pre-normalized data\n",
    "    train_norm = pd.read_csv(\n",
    "        '../a_data_structure/normalized_data/flat/' + cohort + '_X_train_flat_' + otlr_cut + '_otlr_cut_MinMax.tsv',\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "\n",
    "    test_norm = pd.read_csv(\n",
    "        '../a_data_structure/normalized_data/flat/' + cohort + '_X_test_flat_' + otlr_cut + '_otlr_cut_MinMax.tsv',\n",
    "        sep='\\t',\n",
    "        index_col=0)\n",
    "\n",
    "    train_norm_arr = train_norm.to_numpy()\n",
    "    train_norm_arr_exp = np.expand_dims(train_norm_arr, axis=-1)\n",
    "\n",
    "    test_norm_arr = test_norm.to_numpy()\n",
    "    test_norm_arr_exp = np.expand_dims(test_norm_arr, axis=-1)\n",
    "\n",
    "    encoder, decoder, vae = build_model(latent_dim, train_norm_arr)\n",
    "\n",
    "    tf.keras.utils.plot_model(\n",
    "        encoder,\n",
    "        show_shapes=True,\n",
    "        to_file=f'encoder_{cohort}_{otlr_cut}_{epochs}_{batch_size}_1D_model.png')\n",
    "\n",
    "    tf.keras.utils.plot_model(\n",
    "        decoder,\n",
    "        show_shapes=True,\n",
    "        to_file=f\"decoder_{cohort}_{otlr_cut}_{epochs}_{batch_size}_1D_model.png\")\n",
    "\n",
    "    history = vae.fit(x=train_norm_arr_exp, y=train_norm_arr_exp, epochs=epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      validation_data=(test_norm_arr_exp, test_norm_arr_exp))\n",
    "\n",
    "    create_plots(cohort, otlr_cut, latent_dim, batch_size, date, version, history)\n",
    "\n",
    "    trn_ltnt = encoder.predict(train_norm_arr_exp)\n",
    "    tst_ltnt = encoder.predict(test_norm_arr_exp)\n",
    "    trn_dec = decoder.predict(trn_ltnt)\n",
    "    tst_dec = decoder.predict(tst_ltnt)\n",
    "\n",
    "    trn_decDF = pd.DataFrame(np.squeeze(trn_dec))  # hoping the labels map from the raw file, do in UMAP\n",
    "    tst_decDF = pd.DataFrame(np.squeeze(tst_dec))\n",
    "\n",
    "    trn_decDF.to_csv(cohort + '_' +\n",
    "                     # '_pretrain_'+\n",
    "                     otlr_cut + '_outlier_cut_train_' +  # Train <------\n",
    "                     str(epochs) + '_epochs_' +\n",
    "                     str(latent_dim) + '_latent_dim_' +\n",
    "                     date + '_' + version + '.tsv', sep='\\t')\n",
    "\n",
    "    tst_decDF.to_csv(cohort + '_' +\n",
    "                     # '_pretrain_'+\n",
    "                     otlr_cut + '_outlier_cut_test_' +  # Test <------\n",
    "                     str(epochs) + '_epochs_' +\n",
    "                     str(latent_dim) + '_latent_dim_' +\n",
    "                     date + '_' + version + '.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b092bc5-e9b7-47cb-892d-091d311a10c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7842151f-e825-45d6-bd68-2b7dcec19330",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_n = combinations[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6907fc81-0bb0-4618-97f9-22445f5acd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BRCA', '100k', 15, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a685c91f-2152-4d51-902e-49d56a6ba847",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_n = combinations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3727c6c-f3f0-482e-b0ee-f8168beb3cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BRCA', '100k', 15, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7429e6-c6da-4be0-86a8-6cce90a750f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01e6263-d463-4c18-bc3d-bdc2f7551112",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BRCA', '100k', 15, 32),\n",
       " ('BRCA', '100k', 15, 64),\n",
       " ('BRCA', '100k', 15, 128),\n",
       " ('BRCA', '100k', 30, 32),\n",
       " ('BRCA', '100k', 30, 64),\n",
       " ('BRCA', '100k', 30, 128),\n",
       " ('BRCA', '100k', 45, 32),\n",
       " ('BRCA', '100k', 45, 64),\n",
       " ('BRCA', '100k', 45, 128),\n",
       " ('BRCA', '15k', 15, 32),\n",
       " ('BRCA', '15k', 15, 64),\n",
       " ('BRCA', '15k', 15, 128),\n",
       " ('BRCA', '15k', 30, 32),\n",
       " ('BRCA', '15k', 30, 64),\n",
       " ('BRCA', '15k', 30, 128),\n",
       " ('BRCA', '15k', 45, 32),\n",
       " ('BRCA', '15k', 45, 64),\n",
       " ('BRCA', '15k', 45, 128),\n",
       " ('BRCA', '10k', 15, 32),\n",
       " ('BRCA', '10k', 15, 64),\n",
       " ('BRCA', '10k', 15, 128),\n",
       " ('BRCA', '10k', 30, 32),\n",
       " ('BRCA', '10k', 30, 64),\n",
       " ('BRCA', '10k', 30, 128),\n",
       " ('BRCA', '10k', 45, 32),\n",
       " ('BRCA', '10k', 45, 64),\n",
       " ('BRCA', '10k', 45, 128),\n",
       " ('BRCA', '5k', 15, 32),\n",
       " ('BRCA', '5k', 15, 64),\n",
       " ('BRCA', '5k', 15, 128),\n",
       " ('BRCA', '5k', 30, 32),\n",
       " ('BRCA', '5k', 30, 64),\n",
       " ('BRCA', '5k', 30, 128),\n",
       " ('BRCA', '5k', 45, 32),\n",
       " ('BRCA', '5k', 45, 64),\n",
       " ('BRCA', '5k', 45, 128),\n",
       " ('BRCA', '1k', 15, 32),\n",
       " ('BRCA', '1k', 15, 64),\n",
       " ('BRCA', '1k', 15, 128),\n",
       " ('BRCA', '1k', 30, 32),\n",
       " ('BRCA', '1k', 30, 64),\n",
       " ('BRCA', '1k', 30, 128),\n",
       " ('BRCA', '1k', 45, 32),\n",
       " ('BRCA', '1k', 45, 64),\n",
       " ('BRCA', '1k', 45, 128),\n",
       " ('BRCA', '500', 15, 32),\n",
       " ('BRCA', '500', 15, 64),\n",
       " ('BRCA', '500', 15, 128),\n",
       " ('BRCA', '500', 30, 32),\n",
       " ('BRCA', '500', 30, 64),\n",
       " ('BRCA', '500', 30, 128),\n",
       " ('BRCA', '500', 45, 32),\n",
       " ('BRCA', '500', 45, 64),\n",
       " ('BRCA', '500', 45, 128)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvae_venv",
   "language": "python",
   "name": "cvae_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
