{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c127a8d-b952-4f57-8cfe-e5b3f28a0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally, dense_full kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be1a17b-1a32-4b48-b303-dbd736e5c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monday, October 24\n",
    "#Sigmoid activation function within the layers\n",
    "#    range from 0-1 (check) - rational alignment with the normalization strategy\n",
    "#next: (after RobustScaler and UMAP on the 10k outlier clipping) log transform then minmax\n",
    "\n",
    "#How about log transform then Robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0b8b81-14d8-4b2f-9e92-729dddc6e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review norming strat:\n",
    "    \n",
    "#/Users/karlberb/Desktop/RNB00978/sample_count/sample_gen/synthetic_TCGA_data_gen/a_data_structure/normalized_data/flat\n",
    "#is location of the Robust data\n",
    "\n",
    "#/Users/karlberb/Desktop/RNB00978/sample_count/sample_gen/synthetic_TCGA_data_gen/a_data_structure/a_data_structure_04.ipynb\n",
    "#is most recent data prep code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c50a55-39ad-4227-b034-e6bb2df97ea9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1D conv model  \n",
    "\n",
    "clipping the gene expression values around 10k worked ok\n",
    "decoded output file names: (cross referece the loss curves)\n",
    "\n",
    "Production run on 3 outlier clipping models  \n",
    "\n",
    "for BRCA and BLCA\n",
    "\n",
    "From 1Dmodel_00.ipynb\n",
    "    Deconstruction notes and 2D to 1D conversion\n",
    "\n",
    "data:\n",
    "../a_data_structure/normalized_data/flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35304104-d2de-4d80-b54a-40f2b48557dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7f7f95-39ce-426d-9d91-8019624e88c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6c6829-0e82-4bad-859b-2f4757e935a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLCA_X_test_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_no_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_X_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_X_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_X_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_X_train_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_y_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_y_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_y_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_y_train_flat_no_otlr_cut_MinMax.tsv\n"
     ]
    }
   ],
   "source": [
    "ls ../a_data_structure/normalized_data/flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d79119-5303-4c66-a738-2106cedbce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 robust files, by train / test and BLCA, BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e71b30-f55e-4ee4-ba14-de0bc9bd5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Robust\n",
    "\n",
    "# Get the log transform going\n",
    "\n",
    "# Need to spec out an a_data_structure code file for the log transform stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86e0db-3c43-4f20-aa71-b59df439ad57",
   "metadata": {},
   "source": [
    "#wheres the target output?\n",
    "\n",
    "Start making Umaps \n",
    "\n",
    "start with robust BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01a0562-f6fb-406c-96d2-466b4d7105d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/b_model'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bfe930f-f0a3-4d92-9fed-b7b806bf9a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Dconv_devel.ipynb     \u001b[34marchive\u001b[m\u001b[m/               cvae.txt\n",
      "1Dmodel.ipynb          b_1Dmodel_00.ipynb     scp_up_rbust_sclr.txt\n",
      "1Dmodel_01.ipynb       b_model_02.ipynb\n",
      "README.txt             b_model_03.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9026db-58ad-4447-a09d-971a208f8054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: loss_curves_ignored/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls loss_curves_ignored/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b6410db-2477-44df-ad19-a31cd9aaf925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/b_model'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ac0122-852c-491e-8b97-49c6cb0d4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monday, load robust to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9906748f-86e2-48dc-917c-1e43246ca0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1398d32-7d27-4f8d-9b5e-29c39627244a",
   "metadata": {
    "tags": []
   },
   "source": [
    "kernel setup:\n",
    "    \n",
    "    local:\n",
    "        # terminal in project root:\n",
    "        python3 -m venv cvae_venv\n",
    "        source cvae_venv/bin/activate\n",
    "        pip3 install jupyterlab ipykernel matplotlib numpy tensorflow==2.10 keras sklearn pydot graphviz pandas umap-learn imageio tensorflow_probability\n",
    "        which python3\n",
    "        path/to/project_root/cvae_venv/bin/python3 -m ipykernel install --name cvae_venv\n",
    "        # from fresh terminal in project_root, outside venv, select <cvae_venv> kernel at launch\n",
    "        jupyter lab\n",
    "        \n",
    "    Exacloud:\n",
    "        https://wiki.ohsu.edu/display/HACIIAPCS/2022/09/19/JupyterLab+on+Exacloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dec4b8b-6ab8-41f6-91ac-c8a83d2dbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start 500 BLCA - fail, loss explodes after 7 or 8 epochs\n",
    "# skip BRCA fine tune, go to BRCA blank run, need RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be8a66f3-daa6-4268-b3ba-7408b44803da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0496b8f-9d4f-4065-906c-89f412290f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank run START, Data import and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7e4ba82-bd3a-48a3-b0aa-8ec200ddafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "cohorts = [\"BLCA\",\"BRCA\"]\n",
    "otlr_cuts = [\"100k\", \"15k\", \"10k\", \"5k\", \"1k\", \"500\"]\n",
    "epochs = [15, 30 ,45]\n",
    "batch_size = [32, 64, 128]\n",
    "version = '1Dmodel.ipynb'\n",
    "\n",
    "combinations = list(itertools.product(cohorts, otlr_cuts, epochs, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fecdabd-0f7e-40e4-8316-e1a988ddbd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BLCA', '100k', 15, 32),\n",
       " ('BLCA', '100k', 15, 64),\n",
       " ('BLCA', '100k', 15, 128),\n",
       " ('BLCA', '100k', 30, 32),\n",
       " ('BLCA', '100k', 30, 64),\n",
       " ('BLCA', '100k', 30, 128),\n",
       " ('BLCA', '100k', 45, 32),\n",
       " ('BLCA', '100k', 45, 64),\n",
       " ('BLCA', '100k', 45, 128),\n",
       " ('BLCA', '15k', 15, 32),\n",
       " ('BLCA', '15k', 15, 64),\n",
       " ('BLCA', '15k', 15, 128),\n",
       " ('BLCA', '15k', 30, 32),\n",
       " ('BLCA', '15k', 30, 64),\n",
       " ('BLCA', '15k', 30, 128),\n",
       " ('BLCA', '15k', 45, 32),\n",
       " ('BLCA', '15k', 45, 64),\n",
       " ('BLCA', '15k', 45, 128),\n",
       " ('BLCA', '10k', 15, 32),\n",
       " ('BLCA', '10k', 15, 64),\n",
       " ('BLCA', '10k', 15, 128),\n",
       " ('BLCA', '10k', 30, 32),\n",
       " ('BLCA', '10k', 30, 64),\n",
       " ('BLCA', '10k', 30, 128),\n",
       " ('BLCA', '10k', 45, 32),\n",
       " ('BLCA', '10k', 45, 64),\n",
       " ('BLCA', '10k', 45, 128),\n",
       " ('BLCA', '5k', 15, 32),\n",
       " ('BLCA', '5k', 15, 64),\n",
       " ('BLCA', '5k', 15, 128),\n",
       " ('BLCA', '5k', 30, 32),\n",
       " ('BLCA', '5k', 30, 64),\n",
       " ('BLCA', '5k', 30, 128),\n",
       " ('BLCA', '5k', 45, 32),\n",
       " ('BLCA', '5k', 45, 64),\n",
       " ('BLCA', '5k', 45, 128),\n",
       " ('BLCA', '1k', 15, 32),\n",
       " ('BLCA', '1k', 15, 64),\n",
       " ('BLCA', '1k', 15, 128),\n",
       " ('BLCA', '1k', 30, 32),\n",
       " ('BLCA', '1k', 30, 64),\n",
       " ('BLCA', '1k', 30, 128),\n",
       " ('BLCA', '1k', 45, 32),\n",
       " ('BLCA', '1k', 45, 64),\n",
       " ('BLCA', '1k', 45, 128),\n",
       " ('BLCA', '500', 15, 32),\n",
       " ('BLCA', '500', 15, 64),\n",
       " ('BLCA', '500', 15, 128),\n",
       " ('BLCA', '500', 30, 32),\n",
       " ('BLCA', '500', 30, 64),\n",
       " ('BLCA', '500', 30, 128),\n",
       " ('BLCA', '500', 45, 32),\n",
       " ('BLCA', '500', 45, 64),\n",
       " ('BLCA', '500', 45, 128),\n",
       " ('BRCA', '100k', 15, 32),\n",
       " ('BRCA', '100k', 15, 64),\n",
       " ('BRCA', '100k', 15, 128),\n",
       " ('BRCA', '100k', 30, 32),\n",
       " ('BRCA', '100k', 30, 64),\n",
       " ('BRCA', '100k', 30, 128),\n",
       " ('BRCA', '100k', 45, 32),\n",
       " ('BRCA', '100k', 45, 64),\n",
       " ('BRCA', '100k', 45, 128),\n",
       " ('BRCA', '15k', 15, 32),\n",
       " ('BRCA', '15k', 15, 64),\n",
       " ('BRCA', '15k', 15, 128),\n",
       " ('BRCA', '15k', 30, 32),\n",
       " ('BRCA', '15k', 30, 64),\n",
       " ('BRCA', '15k', 30, 128),\n",
       " ('BRCA', '15k', 45, 32),\n",
       " ('BRCA', '15k', 45, 64),\n",
       " ('BRCA', '15k', 45, 128),\n",
       " ('BRCA', '10k', 15, 32),\n",
       " ('BRCA', '10k', 15, 64),\n",
       " ('BRCA', '10k', 15, 128),\n",
       " ('BRCA', '10k', 30, 32),\n",
       " ('BRCA', '10k', 30, 64),\n",
       " ('BRCA', '10k', 30, 128),\n",
       " ('BRCA', '10k', 45, 32),\n",
       " ('BRCA', '10k', 45, 64),\n",
       " ('BRCA', '10k', 45, 128),\n",
       " ('BRCA', '5k', 15, 32),\n",
       " ('BRCA', '5k', 15, 64),\n",
       " ('BRCA', '5k', 15, 128),\n",
       " ('BRCA', '5k', 30, 32),\n",
       " ('BRCA', '5k', 30, 64),\n",
       " ('BRCA', '5k', 30, 128),\n",
       " ('BRCA', '5k', 45, 32),\n",
       " ('BRCA', '5k', 45, 64),\n",
       " ('BRCA', '5k', 45, 128),\n",
       " ('BRCA', '1k', 15, 32),\n",
       " ('BRCA', '1k', 15, 64),\n",
       " ('BRCA', '1k', 15, 128),\n",
       " ('BRCA', '1k', 30, 32),\n",
       " ('BRCA', '1k', 30, 64),\n",
       " ('BRCA', '1k', 30, 128),\n",
       " ('BRCA', '1k', 45, 32),\n",
       " ('BRCA', '1k', 45, 64),\n",
       " ('BRCA', '1k', 45, 128),\n",
       " ('BRCA', '500', 15, 32),\n",
       " ('BRCA', '500', 15, 64),\n",
       " ('BRCA', '500', 15, 128),\n",
       " ('BRCA', '500', 30, 32),\n",
       " ('BRCA', '500', 30, 64),\n",
       " ('BRCA', '500', 30, 128),\n",
       " ('BRCA', '500', 45, 32),\n",
       " ('BRCA', '500', 45, 64),\n",
       " ('BRCA', '500', 45, 128)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7588792-481f-4129-9e0f-d8a2fbb8682f",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c580379-6a7c-4c7e-90d8-6851e5c5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 16:53:17.336072: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1Dconv, do not rebuild in memory - build from fresh kernel only (blank run)\n",
    "import tensorflow as tf; \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import (Input, # want float.64 to go into this layer, two input layers (enc and dec)\n",
    "                          Conv1D,\n",
    "                          Dense,\n",
    "                          Conv1DTranspose,\n",
    "                          Flatten,\n",
    "                          Lambda,\n",
    "                          Reshape)\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.losses import binary_crossentropy\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print('libraries done')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model(train_norm: pd.DataFrame):\n",
    "    latent_dim = 100\n",
    "\n",
    "    def compute_latent(x):\n",
    "    batch = K.shape(mu)[0]\n",
    "    dim = K.int_shape(mu)[1]\n",
    "    eps = K.random_normal(shape=(batch,dim))\n",
    "    return mu + K.exp(sigma/2)*eps\n",
    "\n",
    "def kl_reconstruction_loss(true, pred):                                                  \n",
    "    reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred))\n",
    "    kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "\n",
    "\n",
    "    encoder_input = Input(shape=(train_norm.shape[1],1,))\n",
    "\n",
    "    encoder_conv = Conv1D(filters=8,\n",
    "                      kernel_size=3,\n",
    "                      activation='relu',\n",
    "                      padding='same')(encoder_input)\n",
    "\n",
    "    encoder_conv = Conv1D(filters=16,\n",
    "                      kernel_size=3,\n",
    "                      padding='same',\n",
    "                      activation='relu')(encoder_conv)\n",
    "\n",
    "    encoder = Flatten()(encoder_conv)\n",
    "\n",
    "    mu = Dense(latent_dim)(encoder)\n",
    "    sigma = Dense(latent_dim)(encoder)\n",
    "\n",
    "    latent_space = Lambda(compute_latent, output_shape=(latent_dim,))([mu, sigma])\n",
    "                    \n",
    "    conv_shape = K.int_shape(encoder_conv)\n",
    "\n",
    "    # Decoder start\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "    decoder = Dense(conv_shape[1]*conv_shape[2], activation='relu')(decoder_input)\n",
    "    decoder = Reshape((conv_shape[1], conv_shape[2]))(decoder)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=16,\n",
    "                      kernel_size=3,\n",
    "                      padding='same',\n",
    "                      activation='relu')(decoder)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=8,\n",
    "                      kernel_size=3,\n",
    "                      activation='relu',\n",
    "                      padding='same')(decoder_conv)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=1,\n",
    "                      kernel_size=3,\n",
    "                      activation='relu',\n",
    "                      padding='same')(decoder_conv)\n",
    "\n",
    "    encoder = Model(encoder_input, latent_space)\n",
    "    decoder = Model(decoder_input, decoder_conv)\n",
    "    vae = Model(encoder_input, decoder(encoder(encoder_input)))\n",
    "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)  # blank model set for (pre)training\n",
    "    print('model built')\n",
    "    return encoder, decoder, vae\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b157977-07c4-4aed-96f0-32fd1291173c",
   "metadata": {},
   "source": [
    "## Iterate through all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a365b727-eb1c-4c2b-b879-087c450cbcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 20530)\n",
      "(100, 20530)\n",
      "(299, 20530)\n",
      "(299, 20530, 1)\n",
      "(100, 20530)\n",
      "(100, 20530, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_norm_arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_norm_arr_exp\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 31\u001b[0m encoder, decoder, vae \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_norm_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(encoder\u001b[38;5;241m.\u001b[39msummary())\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoder\u001b[38;5;241m.\u001b[39msummary())\n",
      "Cell \u001b[0;32mIn [19], line 60\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(train_norm)\u001b[0m\n\u001b[1;32m     57\u001b[0m mu \u001b[38;5;241m=\u001b[39m Dense(latent_dim)(encoder)\n\u001b[1;32m     58\u001b[0m sigma \u001b[38;5;241m=\u001b[39m Dense(latent_dim)(encoder)\n\u001b[0;32m---> 60\u001b[0m latent_space \u001b[38;5;241m=\u001b[39m \u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_latent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m conv_shape \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mint_shape(encoder_conv)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Decoder start\u001b[39;00m\n",
      "File \u001b[0;32m~/Development/OHSU/synthetic_TCGA_data_gen/venv/lib/python3.9/site-packages/keras/engine/base_layer_v1.py:838\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m    837\u001b[0m     ):\n\u001b[0;32m--> 838\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOperatorNotAllowedInGraphError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are attempting to use Python control \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflow in a layer that was not declared to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    848\u001b[0m     )\n",
      "File \u001b[0;32m~/Development/OHSU/synthetic_TCGA_data_gen/venv/lib/python3.9/site-packages/keras/layers/core/lambda_layer.py:208\u001b[0m, in \u001b[0;36mLambda.call\u001b[0;34m(self, inputs, mask, training)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m var\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape(\n\u001b[1;32m    206\u001b[0m     watch_accessed_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    207\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m tape, tf\u001b[38;5;241m.\u001b[39mvariable_creator_scope(_variable_creator):\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables(created_variables, tape\u001b[38;5;241m.\u001b[39mwatched_variables())\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn [19], line 19\u001b[0m, in \u001b[0;36mcompute_latent\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_latent\u001b[39m(x):\n\u001b[0;32m---> 19\u001b[0m     batch \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mshape(\u001b[43mmu\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m     dim \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mint_shape(mu)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     21\u001b[0m     eps \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mrandom_normal(shape\u001b[38;5;241m=\u001b[39m(batch,dim))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mu' is not defined"
     ]
    }
   ],
   "source": [
    "for combination in combinations:\n",
    "    cohort = combination[0]\n",
    "    otlr_cut = combination[1]\n",
    "    epochs = combination[2]\n",
    "    batch_size = combination[3]\n",
    "    \n",
    "    # read pre-normalized data\n",
    "    train_norm = pd.read_csv('../a_data_structure/normalized_data/flat/'+cohort+'_X_train_flat_'+otlr_cut+'_otlr_cut_MinMax.tsv',\n",
    "                  sep = '\\t',\n",
    "                   index_col = 0)\n",
    "    \n",
    "    test_norm = pd.read_csv('../a_data_structure/normalized_data/flat/'+cohort+'_X_test_flat_'+otlr_cut+'_otlr_cut_MinMax.tsv',\n",
    "                  sep = '\\t',\n",
    "                   index_col = 0)\n",
    "    \n",
    "    print(train_norm.shape)\n",
    "    \n",
    "    print(test_norm.shape)\n",
    "    \n",
    "    train_norm_arr = train_norm.to_numpy()\n",
    "    train_norm_arr_exp = np.expand_dims(train_norm_arr, axis=-1)\n",
    "    print(train_norm_arr.shape)\n",
    "    print(train_norm_arr_exp.shape)\n",
    "    \n",
    "    test_norm_arr = test_norm.to_numpy()\n",
    "    test_norm_arr_exp = np.expand_dims(test_norm_arr, axis=-1)\n",
    "    \n",
    "    print(test_norm_arr.shape)\n",
    "    print(test_norm_arr_exp.shape)\n",
    "    \n",
    "    encoder, decoder, vae = build_model(train_norm_arr)\n",
    "    print(encoder.summary())\n",
    "    print(decoder.summary())\n",
    "    \n",
    "    tf.keras.utils.plot_model(\n",
    "    encoder,\n",
    "    show_shapes=True, to_file=f'encoder_{cohort}_{otlr_cut}_{epochs}_{batch_size}_1D_model.png')\n",
    "    \n",
    "    tf.keras.utils.plot_model(\n",
    "    decoder,\n",
    "    show_shapes=True,\n",
    "    to_file=f\"decoder_{cohort}_{otlr_cut}_{epochs}_{batch_size}_1D_model.png\")\n",
    "    \n",
    "    \n",
    "    history = vae.fit(x=train_norm_arr_exp, y=train_norm_arr_exp, epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_data=(test_norm_arr_exp, test_norm_arr_exp))\n",
    "    \n",
    "    create_plots(cohort, otlr_cut, latent_dim, batch_size, date, version, history)\n",
    "    \n",
    "    trn_ltnt = encoder.predict(train_norm_arr_exp)\n",
    "    tst_ltnt = encoder.predict(test_norm_arr_exp)\n",
    "    trn_dec = decoder.predict(trn_ltnt)\n",
    "    tst_dec = decoder.predict(tst_ltnt)\n",
    "    \n",
    "    trn_decDF = pd.DataFrame(np.squeeze(trn_dec)) # hoping the labels map from the raw file, do in UMAP\n",
    "    tst_decDF = pd.DataFrame(np.squeeze(tst_dec))\n",
    "    \n",
    "    trn_decDF.to_csv(cohort+'_'+\n",
    "            # '_pretrain_'+\n",
    "            otlr_cut+'_outlier_cut_train_'+ # Train <------\n",
    "            str(epochs)+'_epochs_'+\n",
    "            str(latent_dim)+'_latent_dim_'+\n",
    "            date+'_'+version+'.tsv', sep = '\\t')\n",
    "    \n",
    "    \n",
    "    tst_decDF.to_csv(cohort+'_'+\n",
    "            # '_pretrain_'+\n",
    "            otlr_cut+'_outlier_cut_test_'+ # Test <------\n",
    "            str(epochs)+'_epochs_'+\n",
    "            str(latent_dim)+'_latent_dim_'+\n",
    "            date+'_'+version+'.tsv', sep = '\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f43214-a379-4e10-b172-61cf0c535948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1724163-ab51-41e3-be93-b1da3f336a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(cohort: str, otlr_cut: str, latent_dim: int, batch_size: int, date: str, version: str, history):\n",
    "    plt.plot(history.history['loss'],label=\"loss\")\n",
    "    plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
    "    plt.title(cohort+' embedding loss\\n1D convolutional VAE'\n",
    "          # ' pre-train\\n'+\n",
    "         )\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.annotate('Outliers cut value = '+otlr_cut+\n",
    "             '\\nlatent dim = '+str(latent_dim)+\n",
    "             '\\nBatch size = '+str(batch_size)+\n",
    "             '\\nConvolutional layer count = 2\\nTest ratio = .25\\nNormalization = MinMax',\n",
    "            xy=(.4, .8), xycoords='figure fraction',\n",
    "            horizontalalignment='left', verticalalignment='top',\n",
    "            # fontsize=20\n",
    "            )\n",
    "\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig('loss_curves_ignored/'+cohort+\n",
    "            '_v2_outlier_cut:_'+otlr_cut+\n",
    "            # '_pretrain_'+\n",
    "             ''+\n",
    "            '_epochs:_'+str(epochs)+\n",
    "            '_latent_dim:_'+str(latent_dim)+\n",
    "            date+'_'+version+'.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
