{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c127a8d-b952-4f57-8cfe-e5b3f28a0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally, dense_full kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6be1a17b-1a32-4b48-b303-dbd736e5c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monday, October 24\n",
    "#Sigmoid activation function within the layers\n",
    "#    range from 0-1 (check) - rational alignment with the normalization strategy\n",
    "#next: (after RobustScaler and UMAP on the 10k outlier clipping) log transform then minmax\n",
    "\n",
    "#How about log transform then Robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0b8b81-14d8-4b2f-9e92-729dddc6e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review norming strat:\n",
    "    \n",
    "#/Users/karlberb/Desktop/RNB00978/sample_count/sample_gen/synthetic_TCGA_data_gen/a_data_structure/normalized_data/flat\n",
    "#is location of the Robust data\n",
    "\n",
    "#/Users/karlberb/Desktop/RNB00978/sample_count/sample_gen/synthetic_TCGA_data_gen/a_data_structure/a_data_structure_04.ipynb\n",
    "#is most recent data prep code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c50a55-39ad-4227-b034-e6bb2df97ea9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1D conv model  \n",
    "\n",
    "clipping the gene expression values around 10k worked ok\n",
    "decoded output file names: (cross referece the loss curves)\n",
    "\n",
    "Production run on 3 outlier clipping models  \n",
    "\n",
    "for BRCA and BLCA\n",
    "\n",
    "From 1Dmodel_00.ipynb\n",
    "    Deconstruction notes and 2D to 1D conversion\n",
    "\n",
    "data:\n",
    "../a_data_structure/normalized_data/flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35304104-d2de-4d80-b54a-40f2b48557dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7f7f95-39ce-426d-9d91-8019624e88c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6c6829-0e82-4bad-859b-2f4757e935a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLCA_X_test_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_X_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_X_train_flat_no_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_y_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_100k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_10k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_1M_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_1k_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_500_otlr_cut_MinMax.tsv\n",
      "BLCA_y_train_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_X_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_X_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_X_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_X_train_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_y_test_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_y_test_flat_no_otlr_cut_MinMax.tsv\n",
      "BRCA_y_train_flat_250_otlr_cut_MinMax.tsv\n",
      "BRCA_y_train_flat_no_otlr_cut_MinMax.tsv\n"
     ]
    }
   ],
   "source": [
    "ls ../a_data_structure/normalized_data/flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d79119-5303-4c66-a738-2106cedbce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 robust files, by train / test and BLCA, BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e71b30-f55e-4ee4-ba14-de0bc9bd5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Robust\n",
    "\n",
    "# Get the log transform going\n",
    "\n",
    "# Need to spec out an a_data_structure code file for the log transform stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b86e0db-3c43-4f20-aa71-b59df439ad57",
   "metadata": {},
   "source": [
    "#wheres the target output?\n",
    "\n",
    "Start making Umaps \n",
    "\n",
    "start with robust BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01a0562-f6fb-406c-96d2-466b4d7105d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/b_model'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bfe930f-f0a3-4d92-9fed-b7b806bf9a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Dconv_devel.ipynb                    b_model_02.ipynb\n",
      "1Dmodel.ipynb                         b_model_03.ipynb\n",
      "1Dmodel_01.ipynb                      cvae.txt\n",
      "README.txt                            decoder_BLCA_100k_15_32_1D_model.png\n",
      "\u001b[34marchive\u001b[m\u001b[m/                              encoder_BLCA_100k_15_32_1D_model.png\n",
      "b_1Dmodel_00.ipynb                    scp_up_rbust_sclr.txt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9026db-58ad-4447-a09d-971a208f8054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: loss_curves_ignored/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "ls loss_curves_ignored/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b6410db-2477-44df-ad19-a31cd9aaf925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/b_model'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18ac0122-852c-491e-8b97-49c6cb0d4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monday, load robust to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9906748f-86e2-48dc-917c-1e43246ca0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1398d32-7d27-4f8d-9b5e-29c39627244a",
   "metadata": {
    "tags": []
   },
   "source": [
    "kernel setup:\n",
    "    \n",
    "    local:\n",
    "        # terminal in project root:\n",
    "        python3 -m venv cvae_venv\n",
    "        source cvae_venv/bin/activate\n",
    "        pip3 install jupyterlab ipykernel matplotlib numpy tensorflow==2.10 keras sklearn pydot graphviz pandas umap-learn imageio tensorflow_probability\n",
    "        which python3\n",
    "        path/to/project_root/cvae_venv/bin/python3 -m ipykernel install --name cvae_venv\n",
    "        # from fresh terminal in project_root, outside venv, select <cvae_venv> kernel at launch\n",
    "        jupyter lab\n",
    "        \n",
    "    Exacloud:\n",
    "        https://wiki.ohsu.edu/display/HACIIAPCS/2022/09/19/JupyterLab+on+Exacloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dec4b8b-6ab8-41f6-91ac-c8a83d2dbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start 500 BLCA - fail, loss explodes after 7 or 8 epochs\n",
    "# skip BRCA fine tune, go to BRCA blank run, need RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be8a66f3-daa6-4268-b3ba-7408b44803da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0496b8f-9d4f-4065-906c-89f412290f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank run START, Data import and setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7e4ba82-bd3a-48a3-b0aa-8ec200ddafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "cohorts = [\"BLCA\",\"BRCA\"]\n",
    "otlr_cuts = [\"100k\", \"15k\", \"10k\", \"5k\", \"1k\", \"500\"]\n",
    "epochs = [15, 30 ,45]\n",
    "batch_size = [32, 64, 128]\n",
    "version = '1Dmodel.ipynb'\n",
    "\n",
    "combinations = list(itertools.product(cohorts, otlr_cuts, epochs, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fecdabd-0f7e-40e4-8316-e1a988ddbd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BLCA', '100k', 15, 32),\n",
       " ('BLCA', '100k', 15, 64),\n",
       " ('BLCA', '100k', 15, 128),\n",
       " ('BLCA', '100k', 30, 32),\n",
       " ('BLCA', '100k', 30, 64),\n",
       " ('BLCA', '100k', 30, 128),\n",
       " ('BLCA', '100k', 45, 32),\n",
       " ('BLCA', '100k', 45, 64),\n",
       " ('BLCA', '100k', 45, 128),\n",
       " ('BLCA', '15k', 15, 32),\n",
       " ('BLCA', '15k', 15, 64),\n",
       " ('BLCA', '15k', 15, 128),\n",
       " ('BLCA', '15k', 30, 32),\n",
       " ('BLCA', '15k', 30, 64),\n",
       " ('BLCA', '15k', 30, 128),\n",
       " ('BLCA', '15k', 45, 32),\n",
       " ('BLCA', '15k', 45, 64),\n",
       " ('BLCA', '15k', 45, 128),\n",
       " ('BLCA', '10k', 15, 32),\n",
       " ('BLCA', '10k', 15, 64),\n",
       " ('BLCA', '10k', 15, 128),\n",
       " ('BLCA', '10k', 30, 32),\n",
       " ('BLCA', '10k', 30, 64),\n",
       " ('BLCA', '10k', 30, 128),\n",
       " ('BLCA', '10k', 45, 32),\n",
       " ('BLCA', '10k', 45, 64),\n",
       " ('BLCA', '10k', 45, 128),\n",
       " ('BLCA', '5k', 15, 32),\n",
       " ('BLCA', '5k', 15, 64),\n",
       " ('BLCA', '5k', 15, 128),\n",
       " ('BLCA', '5k', 30, 32),\n",
       " ('BLCA', '5k', 30, 64),\n",
       " ('BLCA', '5k', 30, 128),\n",
       " ('BLCA', '5k', 45, 32),\n",
       " ('BLCA', '5k', 45, 64),\n",
       " ('BLCA', '5k', 45, 128),\n",
       " ('BLCA', '1k', 15, 32),\n",
       " ('BLCA', '1k', 15, 64),\n",
       " ('BLCA', '1k', 15, 128),\n",
       " ('BLCA', '1k', 30, 32),\n",
       " ('BLCA', '1k', 30, 64),\n",
       " ('BLCA', '1k', 30, 128),\n",
       " ('BLCA', '1k', 45, 32),\n",
       " ('BLCA', '1k', 45, 64),\n",
       " ('BLCA', '1k', 45, 128),\n",
       " ('BLCA', '500', 15, 32),\n",
       " ('BLCA', '500', 15, 64),\n",
       " ('BLCA', '500', 15, 128),\n",
       " ('BLCA', '500', 30, 32),\n",
       " ('BLCA', '500', 30, 64),\n",
       " ('BLCA', '500', 30, 128),\n",
       " ('BLCA', '500', 45, 32),\n",
       " ('BLCA', '500', 45, 64),\n",
       " ('BLCA', '500', 45, 128),\n",
       " ('BRCA', '100k', 15, 32),\n",
       " ('BRCA', '100k', 15, 64),\n",
       " ('BRCA', '100k', 15, 128),\n",
       " ('BRCA', '100k', 30, 32),\n",
       " ('BRCA', '100k', 30, 64),\n",
       " ('BRCA', '100k', 30, 128),\n",
       " ('BRCA', '100k', 45, 32),\n",
       " ('BRCA', '100k', 45, 64),\n",
       " ('BRCA', '100k', 45, 128),\n",
       " ('BRCA', '15k', 15, 32),\n",
       " ('BRCA', '15k', 15, 64),\n",
       " ('BRCA', '15k', 15, 128),\n",
       " ('BRCA', '15k', 30, 32),\n",
       " ('BRCA', '15k', 30, 64),\n",
       " ('BRCA', '15k', 30, 128),\n",
       " ('BRCA', '15k', 45, 32),\n",
       " ('BRCA', '15k', 45, 64),\n",
       " ('BRCA', '15k', 45, 128),\n",
       " ('BRCA', '10k', 15, 32),\n",
       " ('BRCA', '10k', 15, 64),\n",
       " ('BRCA', '10k', 15, 128),\n",
       " ('BRCA', '10k', 30, 32),\n",
       " ('BRCA', '10k', 30, 64),\n",
       " ('BRCA', '10k', 30, 128),\n",
       " ('BRCA', '10k', 45, 32),\n",
       " ('BRCA', '10k', 45, 64),\n",
       " ('BRCA', '10k', 45, 128),\n",
       " ('BRCA', '5k', 15, 32),\n",
       " ('BRCA', '5k', 15, 64),\n",
       " ('BRCA', '5k', 15, 128),\n",
       " ('BRCA', '5k', 30, 32),\n",
       " ('BRCA', '5k', 30, 64),\n",
       " ('BRCA', '5k', 30, 128),\n",
       " ('BRCA', '5k', 45, 32),\n",
       " ('BRCA', '5k', 45, 64),\n",
       " ('BRCA', '5k', 45, 128),\n",
       " ('BRCA', '1k', 15, 32),\n",
       " ('BRCA', '1k', 15, 64),\n",
       " ('BRCA', '1k', 15, 128),\n",
       " ('BRCA', '1k', 30, 32),\n",
       " ('BRCA', '1k', 30, 64),\n",
       " ('BRCA', '1k', 30, 128),\n",
       " ('BRCA', '1k', 45, 32),\n",
       " ('BRCA', '1k', 45, 64),\n",
       " ('BRCA', '1k', 45, 128),\n",
       " ('BRCA', '500', 15, 32),\n",
       " ('BRCA', '500', 15, 64),\n",
       " ('BRCA', '500', 15, 128),\n",
       " ('BRCA', '500', 30, 32),\n",
       " ('BRCA', '500', 30, 64),\n",
       " ('BRCA', '500', 30, 128),\n",
       " ('BRCA', '500', 45, 32),\n",
       " ('BRCA', '500', 45, 64),\n",
       " ('BRCA', '500', 45, 128)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7588792-481f-4129-9e0f-d8a2fbb8682f",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c580379-6a7c-4c7e-90d8-6851e5c5dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:36:26.289991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1Dconv, do not rebuild in memory - build from fresh kernel only (blank run)\n",
    "import tensorflow as tf; \n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import (Input, # want float.64 to go into this layer, two input layers (enc and dec)\n",
    "                          Conv1D,\n",
    "                          Dense,\n",
    "                          Conv1DTranspose,\n",
    "                          Flatten,\n",
    "                          Lambda,\n",
    "                          Reshape)\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.losses import binary_crossentropy\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print('libraries done')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_model(latent_dim: int,train_norm: pd.DataFrame):\n",
    "\n",
    "\n",
    "    def compute_latent(x):\n",
    "        batch = K.shape(mu)[0]\n",
    "        dim = K.int_shape(mu)[1]\n",
    "        eps = K.random_normal(shape=(batch,dim))\n",
    "        return mu + K.exp(sigma/2)*eps\n",
    "\n",
    "    def kl_reconstruction_loss(true, pred):                                                  \n",
    "        reconstruction_loss = binary_crossentropy(K.flatten(true), K.flatten(pred))\n",
    "        kl_loss = 1 + sigma - K.square(mu) - K.exp(sigma)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        return K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tf.executing_eagerly()\n",
    "\n",
    "\n",
    "\n",
    "    encoder_input = Input(shape=(train_norm.shape[1],1,))\n",
    "\n",
    "    encoder_conv = Conv1D(filters=8,\n",
    "                      kernel_size=3,\n",
    "                      activation='relu',\n",
    "                      padding='same')(encoder_input)\n",
    "\n",
    "    encoder_conv = Conv1D(filters=16,\n",
    "                      kernel_size=3,\n",
    "                      padding='same',\n",
    "                      activation='relu')(encoder_conv)\n",
    "\n",
    "    encoder = Flatten()(encoder_conv)\n",
    "\n",
    "    mu = Dense(latent_dim)(encoder)\n",
    "    sigma = Dense(latent_dim)(encoder)\n",
    "\n",
    "    latent_space = Lambda(compute_latent, output_shape=(latent_dim,))([mu, sigma])\n",
    "                    \n",
    "    conv_shape = K.int_shape(encoder_conv)\n",
    "\n",
    "    # Decoder start\n",
    "    decoder_input = Input(shape=(latent_dim,))\n",
    "\n",
    "    decoder = Dense(conv_shape[1]*conv_shape[2], activation='relu')(decoder_input)\n",
    "    decoder = Reshape((conv_shape[1], conv_shape[2]))(decoder)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=16,\n",
    "                      kernel_size=3,\n",
    "                      padding='same',\n",
    "                      activation='relu')(decoder)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=8,\n",
    "                      kernel_size=3,\n",
    "                      activation='relu',\n",
    "                      padding='same')(decoder_conv)\n",
    "\n",
    "    decoder_conv = Conv1DTranspose(filters=1,\n",
    "                      kernel_size=3,\n",
    "                      activation='relu',\n",
    "                      padding='same')(decoder_conv)\n",
    "\n",
    "    encoder = Model(encoder_input, latent_space)\n",
    "    decoder = Model(decoder_input, decoder_conv)\n",
    "    vae = Model(encoder_input, decoder(encoder(encoder_input)))\n",
    "    vae.compile(optimizer='adam', loss=kl_reconstruction_loss)  # blank model set for (pre)training\n",
    "    print('model built')\n",
    "    return encoder, decoder, vae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1724163-ab51-41e3-be93-b1da3f336a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(cohort: str, otlr_cut: str, latent_dim: int, batch_size: int, date: str, version: str, history):\n",
    "    plt.plot(history.history['loss'],label=\"loss\")\n",
    "    plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
    "    plt.title(cohort+' embedding loss\\n1D convolutional VAE'\n",
    "          # ' pre-train\\n'+\n",
    "         )\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.annotate('Outliers cut value = '+otlr_cut+\n",
    "             '\\nlatent dim = '+str(latent_dim)+\n",
    "             '\\nBatch size = '+str(batch_size)+\n",
    "             '\\nConvolutional layer count = 2\\nTest ratio = .25\\nNormalization = MinMax',\n",
    "            xy=(.4, .8), xycoords='figure fraction',\n",
    "            horizontalalignment='left', verticalalignment='top',\n",
    "            # fontsize=20\n",
    "            )\n",
    "\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(f'{cohort}_outlier_cut_{otlr_cut}_epochs_{str(epochs)}_latent_dim_{str(latent_dim)}_{date}_{version}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b157977-07c4-4aed-96f0-32fd1291173c",
   "metadata": {},
   "source": [
    "## Iterate through all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365b727-eb1c-4c2b-b879-087c450cbcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 20530)\n",
      "(100, 20530)\n",
      "(299, 20530)\n",
      "(299, 20530, 1)\n",
      "(100, 20530)\n",
      "(100, 20530, 1)\n",
      "model built\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 20530, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 20530, 8)     32          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 20530, 16)    400         ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 328480)       0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          32848100    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          32848100    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 100)          0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 65,696,632\n",
      "Trainable params: 65,696,632\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 328480)            33176480  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 20530, 16)         0         \n",
      "                                                                 \n",
      " conv1d_transpose (Conv1DTra  (None, 20530, 16)        784       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv1d_transpose_1 (Conv1DT  (None, 20530, 8)         392       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_transpose_2 (Conv1DT  (None, 20530, 1)         25        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,177,681\n",
      "Trainable params: 33,177,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 299 samples, validate on 100 samples\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 17:36:34.222566: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-24 17:36:34.251899: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - ETA: 0s - loss: 8071.9177"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/venv/lib/python3.9/site-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 8s 25ms/sample - loss: 8071.9177 - val_loss: 1290.0212\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 5s 18ms/sample - loss: 1021.7038 - val_loss: 1234.8271\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 6s 19ms/sample - loss: 933.2283 - val_loss: 615000.9943\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 5s 18ms/sample - loss: 820.7080 - val_loss: 14940435727.3049\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 6s 19ms/sample - loss: 697.0731 - val_loss: 2267316061691.9146\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 5s 18ms/sample - loss: 604.2805 - val_loss: 44842843542724.7734\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 5s 18ms/sample - loss: 549.3296 - val_loss: 2448801031763099.0000\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 6s 19ms/sample - loss: 518.4961 - val_loss: 224531951205349632.0000\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 6s 18ms/sample - loss: 502.6643 - val_loss: 3187050635532.9038\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 5s 18ms/sample - loss: 485.2974 - val_loss: 34275281383.8041\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 6s 19ms/sample - loss: 470.4022 - val_loss: 44593321897362384.0000\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 6s 18ms/sample - loss: 459.7211 - val_loss: 26138758693.7808\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 6s 19ms/sample - loss: 449.5132 - val_loss: 130258.9611\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 6s 19ms/sample - loss: 439.5938 - val_loss: 135377.0941\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 6s 18ms/sample - loss: 430.0634 - val_loss: 10319909.9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/venv/lib/python3.9/site-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 20530)\n",
      "(100, 20530)\n",
      "(299, 20530)\n",
      "(299, 20530, 1)\n",
      "(100, 20530)\n",
      "(100, 20530, 1)\n",
      "model built\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20530, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 20530, 8)     32          ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 20530, 16)    400         ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 328480)       0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 100)          32848100    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          32848100    ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 100)          0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 65,696,632\n",
      "Trainable params: 65,696,632\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 328480)            33176480  \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 20530, 16)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_3 (Conv1DT  (None, 20530, 16)        784       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_transpose_4 (Conv1DT  (None, 20530, 8)         392       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_transpose_5 (Conv1DT  (None, 20530, 1)         25        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,177,681\n",
      "Trainable params: 33,177,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 299 samples, validate on 100 samples\n",
      "Epoch 1/15\n",
      "299/299 [==============================] - ETA: 0s - loss: 535.8066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/venv/lib/python3.9/site-packages/keras/engine/training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 6s 21ms/sample - loss: 535.8066 - val_loss: 459.5505\n",
      "Epoch 2/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 258.8532 - val_loss: 352.5671\n",
      "Epoch 3/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 281.2229 - val_loss: 210.1342\n",
      "Epoch 4/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 200.2554 - val_loss: 325.1704\n",
      "Epoch 5/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 167.2270 - val_loss: 180.9595\n",
      "Epoch 6/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 123.4280 - val_loss: 112.6023\n",
      "Epoch 7/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 74.1044 - val_loss: 61.2350\n",
      "Epoch 8/15\n",
      "299/299 [==============================] - 4s 14ms/sample - loss: 31.7475 - val_loss: 22.1993\n",
      "Epoch 9/15\n",
      "299/299 [==============================] - 4s 14ms/sample - loss: 15.3743 - val_loss: 21.5816\n",
      "Epoch 10/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 10.7163 - val_loss: 20.5673\n",
      "Epoch 11/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 8.6012 - val_loss: 29.1010\n",
      "Epoch 12/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 7.3367 - val_loss: 24.7275\n",
      "Epoch 13/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 4.9142 - val_loss: 19.6849\n",
      "Epoch 14/15\n",
      "299/299 [==============================] - 4s 13ms/sample - loss: 4.3378 - val_loss: 21.2555\n",
      "Epoch 15/15\n",
      "299/299 [==============================] - 4s 14ms/sample - loss: 3.3903 - val_loss: 29.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kirchgae/Development/OHSU/synthetic_TCGA_data_gen/venv/lib/python3.9/site-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 20530)\n",
      "(100, 20530)\n",
      "(299, 20530)\n",
      "(299, 20530, 1)\n",
      "(100, 20530)\n",
      "(100, 20530, 1)\n",
      "model built\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 20530, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 20530, 8)     32          ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 20530, 16)    400         ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 328480)       0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 100)          32848100    ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 100)          32848100    ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (None, 100)          0           ['dense_6[0][0]',                \n",
      "                                                                  'dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 65,696,632\n",
      "Trainable params: 65,696,632\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 328480)            33176480  \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 20530, 16)         0         \n",
      "                                                                 \n",
      " conv1d_transpose_6 (Conv1DT  (None, 20530, 16)        784       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_transpose_7 (Conv1DT  (None, 20530, 8)         392       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv1d_transpose_8 (Conv1DT  (None, 20530, 1)         25        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,177,681\n",
      "Trainable params: 33,177,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 299 samples, validate on 100 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "for combination in combinations:\n",
    "    cohort = combination[0]\n",
    "    otlr_cut = combination[1]\n",
    "    epochs = combination[2]\n",
    "    batch_size = combination[3]\n",
    "    latent_dim = 100\n",
    "    \n",
    "    # read pre-normalized data\n",
    "    train_norm = pd.read_csv('../a_data_structure/normalized_data/flat/'+cohort+'_X_train_flat_'+otlr_cut+'_otlr_cut_MinMax.tsv',\n",
    "                  sep = '\\t',\n",
    "                   index_col = 0)\n",
    "    \n",
    "    test_norm = pd.read_csv('../a_data_structure/normalized_data/flat/'+cohort+'_X_test_flat_'+otlr_cut+'_otlr_cut_MinMax.tsv',\n",
    "                  sep = '\\t',\n",
    "                   index_col = 0)\n",
    "    \n",
    "    print(train_norm.shape)\n",
    "    \n",
    "    print(test_norm.shape)\n",
    "    \n",
    "    train_norm_arr = train_norm.to_numpy()\n",
    "    train_norm_arr_exp = np.expand_dims(train_norm_arr, axis=-1)\n",
    "    print(train_norm_arr.shape)\n",
    "    print(train_norm_arr_exp.shape)\n",
    "    \n",
    "    test_norm_arr = test_norm.to_numpy()\n",
    "    test_norm_arr_exp = np.expand_dims(test_norm_arr, axis=-1)\n",
    "    \n",
    "    print(test_norm_arr.shape)\n",
    "    print(test_norm_arr_exp.shape)\n",
    "    \n",
    "    encoder, decoder, vae = build_model(latent_dim, train_norm_arr)\n",
    "    print(encoder.summary())\n",
    "    print(decoder.summary())\n",
    "    \n",
    "    tf.keras.utils.plot_model(\n",
    "    encoder,\n",
    "    show_shapes=True, to_file=f'encoder_{cohort}_{otlr_cut}_{epochs}_{batch_size}_1D_model.png')\n",
    "    \n",
    "    tf.keras.utils.plot_model(\n",
    "    decoder,\n",
    "    show_shapes=True,\n",
    "    to_file=f\"decoder_{cohort}_{otlr_cut}_{epochs}_{batch_size}_1D_model.png\")\n",
    "    \n",
    "    \n",
    "    history = vae.fit(x=train_norm_arr_exp, y=train_norm_arr_exp, epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_data=(test_norm_arr_exp, test_norm_arr_exp))\n",
    "    \n",
    "    create_plots(cohort, otlr_cut, latent_dim, batch_size, date, version, history)\n",
    "    \n",
    "    trn_ltnt = encoder.predict(train_norm_arr_exp)\n",
    "    tst_ltnt = encoder.predict(test_norm_arr_exp)\n",
    "    trn_dec = decoder.predict(trn_ltnt)\n",
    "    tst_dec = decoder.predict(tst_ltnt)\n",
    "    \n",
    "    trn_decDF = pd.DataFrame(np.squeeze(trn_dec)) # hoping the labels map from the raw file, do in UMAP\n",
    "    tst_decDF = pd.DataFrame(np.squeeze(tst_dec))\n",
    "    \n",
    "    trn_decDF.to_csv(cohort+'_'+\n",
    "            # '_pretrain_'+\n",
    "            otlr_cut+'_outlier_cut_train_'+ # Train <------\n",
    "            str(epochs)+'_epochs_'+str(batch_size)+'_batch_size_'+\n",
    "            str(latent_dim)+'_latent_dim_'+\n",
    "            date+'_'+version+'.tsv', sep = '\\t')\n",
    "    \n",
    "    \n",
    "    tst_decDF.to_csv(cohort+'_'+\n",
    "            # '_pretrain_'+\n",
    "            otlr_cut+'_outlier_cut_test_'+ # Test <------\n",
    "            str(epochs)+'_epochs_'+str(batch_size)+'_batch_size_'+\n",
    "            str(latent_dim)+'_latent_dim_'+\n",
    "            date+'_'+version+'.tsv', sep = '\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f43214-a379-4e10-b172-61cf0c535948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
