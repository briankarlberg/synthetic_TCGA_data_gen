{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca9cae-66af-48e3-8d7e-69734c84af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From b_step_up\n",
    "# get imports\n",
    "# first e_ notebook for classical ML\n",
    "# this is for Random Forest predictions on the original 5k mad data\n",
    "# template for RF (or other classical ML such as DT) on decoded samples\n",
    "\n",
    "# ops for step-up experiment: read from F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c5f54-5173-4255-b694-e0154efe08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Original baseline F1 scores on 5k feats for plotting - v5, redoing on M1 machine\n",
    "plt_v = plt_v        # 15 is step up\n",
    "\n",
    "re_samp = re_samp\n",
    "trn_tst_splts = trn_tst_splts\n",
    "\n",
    "blnk_frm = pd.DataFrame()\n",
    "\n",
    "for path in paths:\n",
    "    \n",
    "    cohort = path.split('/')[1].split('.')[0]\n",
    "    print(cohort)\n",
    "    # break\n",
    "    df = pd.read_csv(path, sep=\"\\t\", index_col=0)\n",
    "    features = df.iloc[:, 1:].mad().sort_values(ascending=False)[:5000].index\n",
    "    normVals = df[features].max()\n",
    "    vals = df[features]\n",
    "    X_5k = (vals / normVals)\n",
    "    df = pd.concat( [df.Labels, X_5k] , axis = 1) # Overwrite df with 5k mad feats\n",
    "    # break\n",
    "    F1_dct = {}\n",
    "    for j in list(range(0, re_samp)): # 100% sampling rate\n",
    "        X = df.iloc[:, 1:]\n",
    "        y = df.iloc[:, 0]\n",
    "        output = []\n",
    "        for i in list(range(0, trn_tst_splts)): # number of train test splits\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y,\n",
    "                    test_size=0.33,\n",
    "                        )\n",
    "            clf = RandomForestClassifier(max_depth=2, # reset the classifier each time through loop\n",
    "                )\n",
    "            clf.fit(X_train, y_train)\n",
    "            F1_scr = f1_score(y_test, clf.predict(X_test), average='weighted')\n",
    "            output.append(F1_scr) # extracting stats and overwriting, str(clf)\n",
    "                                  \n",
    "        F1_dct['mean'+str(j)] = mean(output)\n",
    "        F1_dct['std'+str(j)] = stdev(output)\n",
    "\n",
    "    chrt_frm = pd.DataFrame(F1_dct, index = [cohort + '_' + str(clf)])\n",
    "    blnk_frm = pd.concat( [blnk_frm, chrt_frm] )\n",
    "    # print('path loop done')\n",
    "\n",
    "print('all done') # no auto-file writing, interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c18b8d-6cea-4649-bf52-d11bcfa8e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "blnk_frm.to_csv('raw_baseline_F1s/5k_r13.tsv', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
